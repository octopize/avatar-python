{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 7: Batch avatarization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we will perform the avatarization on batch of data. This can be useful if you have to much data that can be avatarized in one shot.\n",
    "\n",
    "# TODO: add a schema of the process\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from avatars.client import ApiClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "url = os.environ.get(\"AVATAR_BASE_URL\")\n",
    "username = os.environ.get(\"AVATAR_USERNAME\")\n",
    "password = os.environ.get(\"AVATAR_PASSWORD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the client that you'll be using for all of your requests\n",
    "from avatars.models import (\n",
    "    AvatarizationJobCreate,\n",
    "    AvatarizationParameters,\n",
    "    ImputationParameters,\n",
    ")\n",
    "from avatars.lib.split import get_split_for_batch\n",
    "from typing import Any, Dict, List, Tuple\n",
    "import math\n",
    "\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from avatars.client import ApiClient\n",
    "\n",
    "from avatars.models import (\n",
    "    AvatarizationBatchJobCreate,\n",
    "    AvatarizationBatchParameters,\n",
    "    AvatarizationBatchResult,\n",
    "    AvatarizationJob,\n",
    "    PrivacyMetricsBaseParameters,\n",
    "    PrivacyMetricsBatchJobCreate,\n",
    "    PrivacyMetricsBatchParameters,\n",
    "    PrivacyMetricsJob,\n",
    "    PrivacyMetricsJobCreate,\n",
    "    PrivacyMetricsParameters,\n",
    "    PrivacyBatchDatasetMapping,\n",
    "    SignalBatchDatasetMapping,\n",
    "    SignalMetricsBaseParameters,\n",
    "    SignalMetricsBatchJobCreate,\n",
    "    SignalMetricsBatchParameters,\n",
    ")\n",
    "from avatars.models import ImputeMethod\n",
    "from avatars.api import (\n",
    "    download_sensitive_unshuffled_avatar_from_batch,\n",
    "    upload_batch_and_get_order,\n",
    "    download_avatar_dataset_from_batch_result,\n",
    ")\n",
    "\n",
    "\n",
    "from avatars.lib.split import get_split_for_batch\n",
    "\n",
    "# The following are not necessary to\n",
    "# run avatar but are used in this tutorial\n",
    "import pandas as pd\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Change this to your actual server endpoint, e.g. base_url=\"https://avatar.company.com\"\n",
    "client = ApiClient(base_url=url)\n",
    "client.authenticate(username=username, password=password)\n",
    "\n",
    "# Verify that we can connect to the API server\n",
    "client.health.get_health()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "We will use a subset of the dataset `adult_with_missing`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../fixtures/adult_with_missing.csv\").iloc[:1000, :]\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create some batches with from the df\n",
    "\n",
    "RowLimit = 200\n",
    "\n",
    "training, splits = get_split_for_batch(\n",
    "    df,\n",
    "    row_limit=RowLimit,\n",
    ")\n",
    "print(training.shape)\n",
    "print(len(splits))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Launch batch avatarization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_ref_id, dataset_splited_ids, order = upload_batch_and_get_order(\n",
    "    training, splits, client=client\n",
    ")\n",
    "\n",
    "\n",
    "batch_job = client.jobs.create_avatarization_batch_job(\n",
    "    AvatarizationBatchJobCreate(\n",
    "        parameters=AvatarizationBatchParameters(\n",
    "            training_dataset_id=dataset_ref_id,\n",
    "            dataset_ids=dataset_splited_ids,\n",
    "            k=20,\n",
    "            imputation=ImputationParameters(method=ImputeMethod.mean),\n",
    "        )\n",
    "    )\n",
    ")\n",
    "batch_job = client.jobs.get_avatarization_batch_job(batch_job.id, timeout=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_job = client.jobs.get_avatarization_batch_job(batch_job.id, timeout=10000)\n",
    "batch_job"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Launch privacy metric per batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "privacy_job_ref = client.jobs.create_privacy_metrics_batch_job(\n",
    "    PrivacyMetricsBatchJobCreate(\n",
    "        parameters=PrivacyMetricsBatchParameters(\n",
    "            avatarization_batch_job_id=batch_job.id,\n",
    "            common_parameters=PrivacyMetricsBaseParameters(\n",
    "                imputation=ImputationParameters(method=ImputeMethod.mean)\n",
    "            ),\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "privacy_job = client.jobs.get_privacy_metrics_batch_job(\n",
    "    privacy_job_ref.id, timeout=100000\n",
    ")\n",
    "\n",
    "print(\"Mean metrics\")\n",
    "# print(privacy_job.result.mean_metrics)\n",
    "\n",
    "print(\"Worst metrics\")\n",
    "print(privacy_job.result.worst_metrics)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Launch signal metrics per batch \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_job_ref = client.jobs.create_signal_metrics_batch_job(\n",
    "    SignalMetricsBatchJobCreate(\n",
    "        parameters=SignalMetricsBatchParameters(\n",
    "            avatarization_batch_job_id=batch_job.id,\n",
    "            common_parameters=SignalMetricsBaseParameters(),\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "signal_job = client.jobs.get_signal_metrics_batch_job(signal_job_ref.id)\n",
    "\n",
    "print(\"Mean metrics\")\n",
    "print(signal_job.result.mean_metrics)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Built the anonymized dataset\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the shuflle avatar dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avatars = download_avatar_dataset_from_batch_result(batch_job.result, client=client)\n",
    "avatars"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Get the sensitive unshuffle avatar dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitive_avatars = download_sensitive_unshuffled_avatar_from_batch(\n",
    "    batch_job.result, order=order, client=client\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitive_avatars"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
