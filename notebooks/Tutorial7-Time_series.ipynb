{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3618f53f",
   "metadata": {},
   "source": [
    "# Tutorial 8: Time Series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69b0adf",
   "metadata": {},
   "source": [
    "In this tutorial, we will perform the avatarization of data containing time series variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9af4f0a",
   "metadata": {},
   "source": [
    "## Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6ea71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from avatars.models import (  # noqa: E402\n",
    "    AvatarizationParameters,\n",
    "    AvatarizationTimeSeriesParameters,\n",
    "    AvatarizationWithTimeSeriesJobCreate,\n",
    "    AvatarizationWithTimeSeriesParameters,\n",
    "    FPCAParameters,\n",
    "    JobStatus,\n",
    ")\n",
    "\n",
    "from avatars.client import ApiClient\n",
    "from avatars.models import AvatarizationJobCreate, AvatarizationParameters\n",
    "from avatars.models import ReportCreate\n",
    "from avatars.models import (\n",
    "    PrivacyMetricsWithTimeSeriesJobCreate,\n",
    "    PrivacyMetricsWithTimeSeriesParameters,\n",
    "    PrivacyMetricsParameters,\n",
    "    PrivacyMetricsTimeSeriesParameters,\n",
    "    SignalMetricsTimeSeriesParameters,\n",
    "    SignalMetricsWithTimeSeriesJobCreate,\n",
    "    SignalMetricsWithTimeSeriesParameters,\n",
    "    TimeSeriesSignalMetricsPerDataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8324774a",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = os.environ.get(\"AVATAR_BASE_URL\")\n",
    "username = os.environ.get(\"AVATAR_USERNAME\")\n",
    "password = os.environ.get(\"AVATAR_PASSWORD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3768e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this to your actual server endpoint, e.g. base_url=\"https://avatar.company.com\"\n",
    "client = ApiClient(base_url=url)\n",
    "client.authenticate(username=username, password=password)\n",
    "\n",
    "# Verify that we can connect to the API server\n",
    "client.health.get_health()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f11ba15",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab736ab5",
   "metadata": {},
   "source": [
    "In this tutorial, we use data that contains readings from 3 sensors for 200 individuals. The data is divided into 3 datasets as follows:\n",
    "- `sensors_vanilla.csv`: demographic data on individuals, each line refers to one individual and contains 15 variables (similar to adult data seen in previous tutorials)\n",
    "- `sensors_timeseries1.csv`: time series data for `sensor1` and `sensor2`. The data contains an identifier variable (`id`) and a time variable (`t`). There are several lines for each individual.\n",
    "- `sensors_timeseries2.csv`: time series data for `sensor3`. Note that this time series data can have different timestamps than the other time series and a different number of measurements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7284e76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vanilla_df = pd.read_csv(\"../fixtures/sensors_vanilla.csv\")\n",
    "ts1_df = pd.read_csv(\"../fixtures/sensors_timeseries1.csv\")\n",
    "ts2_df = pd.read_csv(\"../fixtures/sensors_timeseries2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c494db7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vanilla_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea7be40",
   "metadata": {},
   "source": [
    "**Note that the vanilla data contains a column `id` required to link time series data point with each individual.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6599e8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts1_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73af3e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts2_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286d452f",
   "metadata": {},
   "source": [
    "## Overview of data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd513a6",
   "metadata": {},
   "source": [
    "We provide below a basic visualization function to better understand how the time series data look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ef4394",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Tuple\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "\n",
    "def plot_series(\n",
    "    df: pd.DataFrame,\n",
    "    variable_to_plot: str,\n",
    "    id_variable: str,\n",
    "    time_variable: str,\n",
    "    proportion_to_plot: float = 1.0,\n",
    "    n_series_to_plot: Optional[int] = None,\n",
    "    figsize: Tuple[int, int] = (14, 8),\n",
    ") -> matplotlib.figure.Figure:\n",
    "    \"\"\"Plot given series.\"\"\"\n",
    "    if n_series_to_plot is None:\n",
    "        n_series_to_plot = df[id_variable].unique().shape[0]\n",
    "\n",
    "    df_tmp = df.copy()\n",
    "    df_tmp = df_tmp.sort_values(by=[id_variable, time_variable]).reset_index(drop=True)\n",
    "\n",
    "    cmap = plt.get_cmap(\"gist_rainbow\")\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    for id_nb, id_name in enumerate(set(df_tmp[id_variable])):\n",
    "        if id_nb > n_series_to_plot:\n",
    "            break\n",
    "        selected_records = df_tmp[df_tmp[id_variable] == id_name]\n",
    "        n_points = int(proportion_to_plot * len(selected_records))\n",
    "        selected_indices = np.linspace(0, len(selected_records) - 1, num=n_points)\n",
    "\n",
    "        x = selected_records[time_variable].iloc[selected_indices]\n",
    "        y = selected_records[variable_to_plot].iloc[selected_indices]\n",
    "        ax.plot(x, y, color=cmap(id_nb / n_series_to_plot))\n",
    "    ax.set_title(f\"Series for variable {variable_to_plot}\")\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca8e7a5",
   "metadata": {},
   "source": [
    "and we use it to plot sensor data for some individuals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed9a3f1",
   "metadata": {},
   "source": [
    "### `sensor1` data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e22a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = plot_series(\n",
    "    df := ts1_df,\n",
    "    variable_to_plot=\"sensor1\",\n",
    "    id_variable=\"id\",\n",
    "    time_variable=\"t\",\n",
    "    proportion_to_plot=1.0,\n",
    "    n_series_to_plot=None,\n",
    "    figsize=(14, 8),\n",
    ")\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce98daf9",
   "metadata": {},
   "source": [
    "###  `sensor2` data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2466d748",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = plot_series(\n",
    "    df := ts1_df,\n",
    "    variable_to_plot=\"sensor2\",\n",
    "    id_variable=\"id\",\n",
    "    time_variable=\"t\",\n",
    "    proportion_to_plot=1.0,\n",
    "    n_series_to_plot=None,\n",
    "    figsize=(14, 8),\n",
    ")\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14853c7d",
   "metadata": {},
   "source": [
    "### `sensor3` data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e3d133",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = plot_series(\n",
    "    df := ts2_df,\n",
    "    variable_to_plot=\"sensor3\",\n",
    "    id_variable=\"id\",\n",
    "    time_variable=\"t\",\n",
    "    proportion_to_plot=1.0,\n",
    "    n_series_to_plot=None,\n",
    "    figsize=(14, 8),\n",
    ")\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8f954f",
   "metadata": {},
   "source": [
    "Now that we know what data we are maniplating, we can anonymize it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce471a5",
   "metadata": {},
   "source": [
    "## Avatars of time series data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b777223",
   "metadata": {},
   "source": [
    "### Upload data and save datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b75087b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_vanilla = client.pandas_integration.upload_dataframe(vanilla_df)\n",
    "\n",
    "ts_dfs = [\n",
    "    ts1_df,\n",
    "    ts2_df,\n",
    "]  # we put all time series dataframes in a list to simplify further operations\n",
    "datasets_ts = []\n",
    "for ts_df in ts_dfs:\n",
    "    datasets_ts.append(client.pandas_integration.upload_dataframe(ts_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd8cb5b",
   "metadata": {},
   "source": [
    "### Create job and retrieve results\n",
    "\n",
    "This is done in a similar way than for the anonymization of classic tabular data. However, the objects are different. For data containing time series, it is necessary to parameterize a `AvatarizationWithTimeSeriesJobCreate` with parameters of type `AvatarizationWithTimeSeriesParameters`.\n",
    "\n",
    "The attributes to specify in `AvatarizationWithTimeSeriesParameters` are:\n",
    "- `k`\n",
    "- the dataset_id of the vanilla dataset (i.e. the individual-centric dataset containing one line per individual)\n",
    "- a list of `AvatarizationTimeSeriesParameters` containing 1 item per time series dataset.\n",
    "\n",
    "\n",
    "Each `AvatarizationTimeSeriesParameters` specifies the dataset_id of the time series data and the projection parameters. The projection parameters defines how the data will be transformed (aka projected) so that avatars can be generated. \n",
    "\n",
    "Supported time series projection is Functional Principal Component Analysis (FPCA). `nf` is the number of components used to represent each time series variable in the projection.\n",
    "\n",
    "Note that it is possible to generate avatars of data containing only time series dataset (i.e. without any vanilla data). In this case, dataset_id can be set to `None`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2e0dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "job = client.jobs.create_avatarization_with_time_series_job(\n",
    "    AvatarizationWithTimeSeriesJobCreate(\n",
    "        parameters=AvatarizationWithTimeSeriesParameters(\n",
    "            vanilla_dataset_id=dataset_vanilla.id,\n",
    "            k=5,\n",
    "            time_series=[\n",
    "                AvatarizationTimeSeriesParameters(\n",
    "                    dataset_id=dataset_ts.id,\n",
    "                    projection_parameters=FPCAParameters(\n",
    "                        nf=10,\n",
    "                    ),\n",
    "                )\n",
    "                for dataset_ts in datasets_ts\n",
    "            ],\n",
    "        )\n",
    "    ),\n",
    "    timeout=50,\n",
    ")\n",
    "job = client.jobs.get_avatarization_time_series_job(job.id, timeout=60)\n",
    "print(job.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcb90e2",
   "metadata": {},
   "source": [
    "### Retrieve avatars\n",
    "\n",
    "Once generated, the avatar dataset are stored on the server and can be retrieved using theuir dataset ID. The dataset ID  for each avatar dataset is contained in `job.result.datasets`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba52153",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"There are {len(job.result.datasets)} avatars datasets following anonymization.\\n\"\n",
    ")\n",
    "\n",
    "print(f\"Their UUIDs are : {[x.avatars_dataset.id for x in job.result.datasets]}\\n\")\n",
    "\n",
    "originals_to_avatars = {\n",
    "    x.original_id: x.avatars_dataset.id for x in job.result.datasets\n",
    "}\n",
    "print(f\"The mapping original to avatar is: {originals_to_avatars}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532eab9e",
   "metadata": {},
   "source": [
    "### Checking your avatars: vanilla data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46228cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "avatars_vanilla_df = client.pandas_integration.download_dataframe(\n",
    "    job.result.datasets[0].avatars_dataset.id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a13405",
   "metadata": {},
   "outputs": [],
   "source": [
    "avatars_vanilla_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28918823",
   "metadata": {},
   "source": [
    "### Checking your avatars: `sensor1` and `sensor2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440dda51",
   "metadata": {},
   "outputs": [],
   "source": [
    "avatars_ts1_df = client.pandas_integration.download_dataframe(\n",
    "    job.result.datasets[1].avatars_dataset.id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9653d3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = plot_series(\n",
    "    df := avatars_ts1_df,\n",
    "    variable_to_plot=\"sensor1\",\n",
    "    id_variable=\"id\",\n",
    "    time_variable=\"t\",\n",
    "    proportion_to_plot=1.0,\n",
    "    n_series_to_plot=None,\n",
    "    figsize=(14, 8),\n",
    ")\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb9fde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = plot_series(\n",
    "    df := avatars_ts1_df,\n",
    "    variable_to_plot=\"sensor2\",\n",
    "    id_variable=\"id\",\n",
    "    time_variable=\"t\",\n",
    "    proportion_to_plot=1.0,\n",
    "    n_series_to_plot=None,\n",
    "    figsize=(14, 8),\n",
    ")\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d118c2a",
   "metadata": {},
   "source": [
    "### Checking your avatars: `sensor3`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897e9458",
   "metadata": {},
   "outputs": [],
   "source": [
    "avatars_ts2_df = client.pandas_integration.download_dataframe(\n",
    "    job.result.datasets[2].avatars_dataset.id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0eca9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = plot_series(\n",
    "    df := avatars_ts2_df,\n",
    "    variable_to_plot=\"sensor3\",\n",
    "    id_variable=\"id\",\n",
    "    time_variable=\"t\",\n",
    "    proportion_to_plot=1.0,\n",
    "    n_series_to_plot=None,\n",
    "    figsize=(14, 8),\n",
    ")\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7781c4cb",
   "metadata": {},
   "source": [
    "## Privacy metrics for time series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46773eb1",
   "metadata": {},
   "source": [
    "As for any data, privacy metrics need to be computed on the output time series data to confirm that it is anonymous. We first retrieve the data required by the privacy metrics, that is the original datasets and their sensitive unshuffled counterparts. The unshuffled datasets are only used for computing the privacy metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b549d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we get the unshuffled vanilla avatars from the job result based on the original id\n",
    "vanilla_unshuffled_avatars = [\n",
    "    result.sensitive_unshuffled_avatars_datasets\n",
    "    for result in job.result.datasets\n",
    "    if result.original_id == dataset_vanilla.id\n",
    "][0]\n",
    "\n",
    "# we get the unshuffled time series avatars from the job result based on their original ids\n",
    "dataset_pairs = [\n",
    "    (result.original_id, result.sensitive_unshuffled_avatars_datasets)\n",
    "    for result in job.result.datasets\n",
    "    if result.original_id != dataset_vanilla.id\n",
    "]\n",
    "ts_original_ids = [pair[0] for pair in dataset_pairs]\n",
    "ts_unshuffled_avatars = [pair[1] for pair in dataset_pairs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3798e165",
   "metadata": {},
   "outputs": [],
   "source": [
    "privacy_job = client.jobs.create_privacy_metrics_time_series_job(\n",
    "    PrivacyMetricsWithTimeSeriesJobCreate(\n",
    "        parameters=PrivacyMetricsWithTimeSeriesParameters(\n",
    "            vanilla_original_id=dataset_vanilla.id,\n",
    "            vanilla_unshuffled_avatars_id=vanilla_unshuffled_avatars.id,\n",
    "            time_series=[\n",
    "                PrivacyMetricsTimeSeriesParameters(\n",
    "                    dataset_id=original_id,\n",
    "                    unshuffled_avatar_dataset_id=avatar.id,\n",
    "                    projection_parameters=FPCAParameters(nf=3),\n",
    "                )\n",
    "                for original_id, avatar in zip(ts_original_ids, ts_unshuffled_avatars)\n",
    "            ],\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "privacy_job = client.jobs.get_privacy_metrics_time_series_job(\n",
    "    privacy_job.id, timeout=10\n",
    ")\n",
    "print(privacy_job.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3756eb84",
   "metadata": {},
   "source": [
    "Metric results are calculated for each dataset and are stored in `privacy_job.result`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc07343",
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric_details in privacy_job.result.details:\n",
    "    print(\"-------------\")\n",
    "    print(f\"Metrics for avatar of original dataset {metric_details.original_id} are: \")\n",
    "    print(metric_details)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47055623",
   "metadata": {},
   "source": [
    "## Signal metrics for time series data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86994b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_job = client.jobs.create_signal_metrics_time_series_job(\n",
    "    SignalMetricsWithTimeSeriesJobCreate(\n",
    "        parameters=SignalMetricsWithTimeSeriesParameters(\n",
    "            vanilla_original_id=dataset_vanilla.id,\n",
    "            vanilla_avatars_id=vanilla_unshuffled_avatars.id,\n",
    "            time_series=[\n",
    "                SignalMetricsTimeSeriesParameters(\n",
    "                    dataset_id=original_id,\n",
    "                    avatar_dataset_id=avatar.id,\n",
    "                )\n",
    "                for original_id, avatar in zip(ts_original_ids, ts_unshuffled_avatars)\n",
    "            ],\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "signal_job = client.jobs.get_signal_metrics_time_series_job(signal_job.id, timeout=10)\n",
    "print(signal_job.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0370b9",
   "metadata": {},
   "source": [
    "Metric results are calculated for each dataset and are stored in `signal_job.result`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fad2a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric_details in signal_job.result.details:\n",
    "    print(\"-------------\")\n",
    "    print(f\"Metrics for avatar of original dataset {metric_details.original_id} are: \")\n",
    "    print(metric_details)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
