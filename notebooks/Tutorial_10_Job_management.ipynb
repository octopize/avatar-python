{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7d46ba6",
   "metadata": {},
   "source": [
    "# Tutorial 10: Job management"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f021c65",
   "metadata": {},
   "source": [
    "In this tutorial, we show how to manage the jobs that a user creates. Poor job management can lead to the creation of long queues of jobs on the server side, preventing new jobs to start. \n",
    "\n",
    "It is particularly important when executing large jobs or trying out many parameters. The execution of some may take longer than expected and a user may want to stop them to enable the start of other ones.\n",
    "\n",
    "Here are a few situations that can be unlocked by \"cleaning\" the job queue: \n",
    "- None of my submitted jobs get started\n",
    "- I have launched a job with the wrong parameters and I realize it will take a long time\n",
    "- I urgently need to run a job but larger jobs are already in the queue.\n",
    "- etc..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2dc29da",
   "metadata": {},
   "source": [
    "# Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7b90d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "url = os.environ.get(\"AVATAR_BASE_URL\")\n",
    "username = os.environ.get(\"AVATAR_USERNAME\")\n",
    "password = os.environ.get(\"AVATAR_PASSWORD\")\n",
    "\n",
    "# This is the client that you'll be using for all of your requests\n",
    "from avatars.client import ApiClient\n",
    "from avatars.models import AvatarizationJobCreate, AvatarizationParameters\n",
    "from avatars.models import ReportCreate\n",
    "from avatars.models import JobStatus\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import io\n",
    "\n",
    "# Change this to your actual server endpoint, e.g. base_url=\"https://avatar.company.com\"\n",
    "client = ApiClient(base_url=url)\n",
    "client.authenticate(username=username, password=password)\n",
    "\n",
    "# Verify that we can connect to the API server\n",
    "client.health.get_health()\n",
    "\n",
    "# Verify that the client is compatible.\n",
    "client.compatibility.is_client_compatible()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13c5eeb",
   "metadata": {},
   "source": [
    "# Job creation\n",
    "\n",
    "Let us create one job for demonstration purposes. This step may not be necessary if you have already created jobs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98474604",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../fixtures/iris.csv\")\n",
    "\n",
    "dataset = client.pandas_integration.upload_dataframe(df)\n",
    "\n",
    "avatarization_job = client.jobs.create_avatarization_job(\n",
    "    AvatarizationJobCreate(\n",
    "        parameters=AvatarizationParameters(k=20, dataset_id=dataset.id),\n",
    "    )\n",
    ")\n",
    "print(avatarization_job.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caeb3d4f",
   "metadata": {},
   "source": [
    "## View jobs created"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910c7b1a",
   "metadata": {},
   "source": [
    "#### Get all jobs (ordered by creation date descending)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bf6472",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = client.jobs.find_all_jobs_by_user()\n",
    "jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7abe93a6",
   "metadata": {},
   "source": [
    "#### Number of jobs created by the logged user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81680326",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(jobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9744fcb4",
   "metadata": {},
   "source": [
    "#### Get last created job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb9c95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a7139a",
   "metadata": {},
   "source": [
    "#### Get all pending jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f19cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pending_jobs = [job for job in jobs if job.status == JobStatus.pending]\n",
    "print(f\"There are {len(pending_jobs)} pending jobs.\")\n",
    "pending_jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0dc3de",
   "metadata": {},
   "source": [
    "#### Get all failed jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22767238",
   "metadata": {},
   "outputs": [],
   "source": [
    "failed_jobs = [job for job in jobs if job.status == JobStatus.failure]\n",
    "print(f\"There are {len(failed_jobs)} failed jobs.\")\n",
    "failed_jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb4864a",
   "metadata": {},
   "source": [
    "You may be interested in the reason(s) why those jobs have failed. For this, the error message can be accessed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c30c174",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_messages = [job.error_message for job in jobs if job.status == JobStatus.failure]\n",
    "for error in error_messages:\n",
    "    print(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57777290",
   "metadata": {},
   "source": [
    "#### Get all killed jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac8d364",
   "metadata": {},
   "outputs": [],
   "source": [
    "killed_jobs = [job for job in jobs if job.status == JobStatus.killed]\n",
    "print(f\"There are {len(killed_jobs)} pending jobs.\")\n",
    "killed_jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f1447a",
   "metadata": {},
   "source": [
    "#### Get all started jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b147b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "started_jobs = [job for job in jobs if job.status == JobStatus.started]\n",
    "print(f\"There are {len(started_jobs)} pending jobs.\")\n",
    "started_jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b372d6b8",
   "metadata": {},
   "source": [
    "## Cancel jobs\n",
    "\n",
    "Jobs submitted by users are queued before being executed. Several jobs can be executed in parallel but there is  a limit on how many. For this reason, managing created jobs is essential to enable the successful completion of additional jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee7d76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get last created job\n",
    "last_job_id = jobs[0].id\n",
    "print(last_job_id)\n",
    "\n",
    "# cancel it\n",
    "last_job = client.jobs.cancel_job(last_job_id)\n",
    "\n",
    "# the status of that job is now `killed`.\n",
    "last_job.status"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2a29cb",
   "metadata": {},
   "source": [
    "## View datasets\n",
    "\n",
    "It may also be useful to manage datasets to avoid unnecessary upload of the same data for example. The `find_all_datasets_by_user()` function will give you all datasets for which you have access with some basic statistics such as number of lines and dimensions. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f62996",
   "metadata": {},
   "source": [
    "#### Get all datasets of the user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154f46ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.datasets.find_all_datasets_by_user()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c605437a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(client.datasets.find_all_datasets_by_user())"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
